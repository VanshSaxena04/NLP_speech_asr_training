{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322398c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segments from train_manifest.jsonl...\n",
      "Analyzing 5941 segments for disfluencies...\n",
      "Total disfluency occurrences detected: 8497\n",
      "Disfluency metadata saved to: disfluency_detections.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "step3_detect_disfluencies.py\n",
    "\n",
    "Step 3: Analyze the segment-level manifest (train_manifest.jsonl) for disfluency patterns\n",
    "and generate the structured disfluency dataset (CSV).\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "# Assuming your output from Step 1/2 is in ./data/processed/\n",
    "INPUT_MANIFEST = \"train_manifest.jsonl\" # Use the file you uploaded\n",
    "OUTPUT_CSV = \"disfluency_detections.csv\" \n",
    "\n",
    "# -----------------------------\n",
    "# Disfluency Patterns for Hindi (Devanagari)\n",
    "# -----------------------------\n",
    "\n",
    "# List of common fillers (isolated words)\n",
    "# Adding 'हम्', 'एह', 'जी' (when used as filler)\n",
    "FILLERS = [\n",
    "    \"हूँ\", \"हम्\", \"हम्म\", \"उम्म\", \"अह\", \"एह\", \"जी\", \"हाँ\", \"ठीक है\", \"मतलब\", \"तो\", \"बस\"\n",
    "]\n",
    "\n",
    "# 1. Repetitions: Look for a word/phrase repeated, often separated by a marker.\n",
    "# Simple pattern: (Word)(Marker)(Word)\n",
    "# (\\S+) captures one or more non-whitespace chars (the word/token).\n",
    "# (?:\\.\\.\\.|\\s+-\\s*|\\s+) is a non-capturing group for the pause marker (..., or space-dash-space).\n",
    "# \\s*\\1 looks for optional whitespace followed by the captured word/phrase (\\1).\n",
    "REPETITION_REGEX = re.compile(r\"(\\S+)(?:\\.\\.\\.|\\s+-\\s*|\\s+)\\s*\\1\", re.IGNORECASE)\n",
    "\n",
    "# 2. Hesitations / False Starts / Pauses: Marked by ellipsis or just a trailing pause\n",
    "HESITATION_REGEX = re.compile(r\"\\.\\.\\.|\\.\\s+\", re.IGNORECASE)\n",
    "\n",
    "# 3. Prolongations: Find any vowel or nasal sound repeated 3 or more times consecutively\n",
    "# Vowels/Matras in Devanagari: ा, ि, ी, ु, ू, ृ, े, ै, ो, ौ, ं, ँ\n",
    "PROLONGATION_REGEX = re.compile(r\"([ािीुूृेैोौंँ])\\1{2,}\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def detect_disfluencies(text: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Analyzes a single segment text for disfluency patterns.\"\"\"\n",
    "    detections = []\n",
    "    \n",
    "    # Clean text for simple filler/token checking (remove punctuation for comparison)\n",
    "    cleaned_text = re.sub(r'[.,?!:;\\'\"]', '', text)\n",
    "    text_tokens = cleaned_text.split()\n",
    "    \n",
    "    # 1. Filler Detection (isolated word check)\n",
    "    for token in text_tokens:\n",
    "        if token in FILLERS:\n",
    "            detections.append({\n",
    "                \"disfluency_type\": \"filler\",\n",
    "                \"detected_token\": token,\n",
    "                \"confidence\": 0.9 \n",
    "            })\n",
    "    \n",
    "    # 2. Repetition Detection\n",
    "    for match in REPETITION_REGEX.finditer(text):\n",
    "        detections.append({\n",
    "            \"disfluency_type\": \"repetition\",\n",
    "            \"detected_token\": match.group(0).strip(),\n",
    "            \"confidence\": 0.8 \n",
    "        })\n",
    "\n",
    "    # 3. Hesitation/False Start Detection (Ellipsis-based)\n",
    "    for match in HESITATION_REGEX.finditer(text):\n",
    "        token = match.group(0).strip()\n",
    "        # Simple check to avoid recording an ellipsis if it's part of a detected repetition\n",
    "        is_part_of_repetition = any(d[\"disfluency_type\"] == \"repetition\" and token in d[\"detected_token\"] for d in detections)\n",
    "        if not is_part_of_repetition:\n",
    "            detections.append({\n",
    "                \"disfluency_type\": \"hesitation/false_start\",\n",
    "                \"detected_token\": token,\n",
    "                \"confidence\": 0.7 \n",
    "            })\n",
    "\n",
    "    # 4. Prolongation Detection\n",
    "    for match in PROLONGATION_REGEX.finditer(text):\n",
    "        detections.append({\n",
    "            \"disfluency_type\": \"prolongation\",\n",
    "            \"detected_token\": match.group(0),\n",
    "            \"confidence\": 0.9 \n",
    "        })\n",
    "\n",
    "    # Deduplicate based on type and detected token for clean output\n",
    "    unique_detections = []\n",
    "    seen = set()\n",
    "    for d in detections:\n",
    "        key = (d[\"disfluency_type\"], d[\"detected_token\"])\n",
    "        if key not in seen:\n",
    "            unique_detections.append(d)\n",
    "            seen.add(key)\n",
    "    \n",
    "    return unique_detections\n",
    "\n",
    "def main():\n",
    "    if not Path(INPUT_MANIFEST).exists():\n",
    "        print(f\"[ERROR] Input manifest not found: {INPUT_MANIFEST}. Please ensure it is in the current directory.\")\n",
    "        return\n",
    "\n",
    "    segments = []\n",
    "    print(f\"Loading segments from {INPUT_MANIFEST}...\")\n",
    "    with open(INPUT_MANIFEST, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            segments.append(json.loads(line))\n",
    "\n",
    "    all_disfluencies = []\n",
    "    print(f\"Analyzing {len(segments)} segments for disfluencies...\")\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        text = segment.get(\"text\", \"\")\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        disfluencies = detect_disfluencies(text)\n",
    "\n",
    "        for disfluency in disfluencies:\n",
    "            # Combine segment metadata with disfluency details\n",
    "            row = {\n",
    "                \"row_id\": len(all_disfluencies) + 1,\n",
    "                \"recording_id\": segment[\"recording_id\"],\n",
    "                \"segment_id\": segment[\"segment_id\"],\n",
    "                # The segment's start/end time in the original audio\n",
    "                \"start_time\": segment[\"start_time\"], \n",
    "                \"end_time\": segment[\"end_time\"],     \n",
    "                \"duration\": segment[\"duration\"],\n",
    "                \"disfluency_type\": disfluency[\"disfluency_type\"],\n",
    "                \"detected_token\": disfluency[\"detected_token\"],\n",
    "                \"confidence\": disfluency[\"confidence\"],\n",
    "                \"audio_url\": segment[\"audio_filepath\"], # original full audio URL for clipping\n",
    "                # Placeholder for the final clip path\n",
    "                \"clip_path\": f\"clips/{segment['segment_id']}.wav\",\n",
    "                \"notes\": f\"Found {disfluency['disfluency_type']} near token(s): '{disfluency['detected_token']}'\"\n",
    "            }\n",
    "            all_disfluencies.append(row)\n",
    "\n",
    "    print(f\"Total disfluency occurrences detected: {len(all_disfluencies)}\")\n",
    "    \n",
    "    # Final Output Dataset (Sheet Format)\n",
    "    output_df = pd.DataFrame(all_disfluencies)\n",
    "    \n",
    "    # Ensure correct column order for the deliverable sheet\n",
    "    column_order = [\n",
    "        \"row_id\", \"recording_id\", \"segment_id\", \"disfluency_type\", \n",
    "        \"detected_token\", \"start_time\", \"end_time\", \"duration\", \n",
    "        \"clip_path\", \"confidence\", \"notes\", \"audio_url\" # audio_url is for internal use in clipping\n",
    "    ]\n",
    "    \n",
    "    if not output_df.empty:\n",
    "        output_df = output_df.reindex(columns=column_order)\n",
    "    \n",
    "    output_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n",
    "    print(f\"Disfluency metadata saved to: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have pandas installed: pip install pandas\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442ed79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
